{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9f01c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "447ea5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "photo1 = cv2.imread(\"women_face.jpg\")\n",
    "photo2 = cv2.imread('face_shape_women_round-sm.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "510f7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "photo1 = cv2.resize(photo1,(500,500))\n",
    "photo2 = cv2.resize(photo2,(500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d1769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img1', photo1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217b82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img2', photo2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9b81763",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2b7a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces  = model.detectMultiScale(photo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b9373d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5528e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = faces[0][0]\n",
    "y1 = faces[0][1]\n",
    "x2 = x1 + faces[0][2]\n",
    "y2 = y1 + faces[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfcb4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cp = photo[x1:x2 , y1:y2]\n",
    "#cp = photo[150:y2 , 231:x2]\n",
    "cp1 = photo1[y1:y2 , x1:x2]\n",
    "cp2 = photo2[y1:y2 , x1:x2] =cp1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05076090",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('rec', photo2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aea9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
